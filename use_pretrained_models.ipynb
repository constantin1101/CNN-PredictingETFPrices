{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constantinernstberger/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "2023-12-31 14:31:14.594536: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
    "from keras.models import load_model\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMEFRAMES = [14, 30, 90, 180, 365]\n",
    "PREDICTIONS = [5, 30, 90]\n",
    "IMG_TYPES = ['OHLC', 'ColoredOHLC', 'Line', 'AlgoTrading']\n",
    "NEW_DATA = ['SmallCap', 'Russell2000', 'Treasury']\n",
    "\n",
    "labels = pd.read_csv('transfer_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the images using the bounding boxes\n",
    "def crop_image(img_path):\n",
    "    # Load the image in grayscale\n",
    "    img = cv2.imread(img_path, 0)\n",
    "\n",
    "    # Check if the image was loaded correctly\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image at {img_path} not found. Please check the path.\")\n",
    "\n",
    "    # Use regular expression to match numbers followed by \".png\" at the end of the filename\n",
    "    match = re.search(r'(\\d+)(?=\\.png$)', img_path)\n",
    "    \n",
    "    # Check if we found a match\n",
    "    if match:\n",
    "        # Extract the number from the matched group\n",
    "        number = int(match.group(1))\n",
    "        \n",
    "        # Check if the number is one of the specified values\n",
    "        if number == 14:\n",
    "            # Crop the image using the bounding rectangle\n",
    "            crop = img[100:100+120, 80:80+85]\n",
    "        elif number == 30:\n",
    "            # Crop the image using the bounding rectangle\n",
    "            crop = img[100:100+120, 80:80+132]\n",
    "        elif number == 90:\n",
    "            # Crop the image using the bounding rectangle\n",
    "            crop = img[100:100+120, 80:80+226]\n",
    "        elif number == 180:\n",
    "            # Crop the image using the bounding rectangle\n",
    "            crop = img[100:100+120, 80:80+414]\n",
    "        elif number == 365:\n",
    "            # Crop the image using the bounding rectangle\n",
    "            crop = img[100:100+120, 80:80+602]\n",
    "    return crop\n",
    "\n",
    "# Example usage:\n",
    "filenames = labels['Image'].values.tolist()\n",
    "\n",
    "# Testing the function with the provided list of filenames\n",
    "for name in filenames:\n",
    "    try:\n",
    "        cropped_image = crop_image(name)\n",
    "        # Construct the new path for the cropped image\n",
    "        new_path = name.replace('.png', '_cropped.png')\n",
    "        # Save the cropped image\n",
    "        cv2.imwrite(new_path, cropped_image)\n",
    "    except ValueError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jx/r9zzxsjd7wxgmmn32r0l8cz40000gn/T/ipykernel_45131/666818149.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  labels['Image'] = labels['Image'].str.replace('.png', '_cropped.png')\n"
     ]
    }
   ],
   "source": [
    "# Create a new column called 'Image' that contains the path to the cropped image but only if they \n",
    "labels['Image'] = labels['Image'].str.replace('.png', '_cropped.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and convert an image to grayscale\n",
    "def load_image(image_path):\n",
    "    # Load image in grayscale\n",
    "    image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Unable to load image at path: {image_path}\")\n",
    "    return image\n",
    "\n",
    "filenames = labels['Image'].values.tolist()\n",
    "\n",
    "images = []\n",
    "\n",
    "for name in filenames:\n",
    "    try:\n",
    "        img = load_image(name)\n",
    "        images.append(img)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "# Add a new column to the labels DataFrame to store the image arrays\n",
    "labels['Image_Array'] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2100\n",
      "0    1800\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show the number of 1s and 0s in the dataset\n",
    "print(labels['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Image  TimePrediction  \\\n",
      "0     images/OHLC/SmallCap_2019-02-01 00:00:00_14_cr...               5   \n",
      "1005  images/ColoredOHLC/SmallCap_2019-02-01 00:00:0...               5   \n",
      "1006  images/ColoredOHLC/SmallCap_2019-02-01 00:00:0...              30   \n",
      "1063  images/ColoredOHLC/SmallCap_2019-02-01 00:00:0...               5   \n",
      "1064  images/ColoredOHLC/SmallCap_2019-02-01 00:00:0...              30   \n",
      "\n",
      "      LastPrice  FuturePrice  Label  \\\n",
      "0     76.620003    76.860001      1   \n",
      "1005  76.620003    76.860001      1   \n",
      "1006  76.620003    79.650002      1   \n",
      "1063  76.620003    76.860001      1   \n",
      "1064  76.620003    79.650002      1   \n",
      "\n",
      "                                            Image_Array       Date  \n",
      "0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2019-02-01  \n",
      "1005  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2019-02-01  \n",
      "1006  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2019-02-01  \n",
      "1063  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2019-02-01  \n",
      "1064  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... 2019-02-01  \n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by date\n",
    "labels['Date'] = labels['Image'].str.extract(r'(\\d{4}-\\d{2}-\\d{2})')\n",
    "labels['Date'] = pd.to_datetime(labels['Date'])\n",
    "labels = labels.sort_values(by='Date') \n",
    "print(labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(columns=['Image_Type', 'Timeframe', 'Prediction', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Hit_Rate', 'Average_RoR'])\n",
    "\n",
    "TIMEFRAMES = [14, 30, 90, 180, 365]\n",
    "PREDICTIONS = [5, 30, 90]\n",
    "IMG_TYPES = ['OHLC', 'ColoredOHLC', 'Line', 'AlgoTrading']\n",
    "\n",
    "for img_type in IMG_TYPES:\n",
    "    for timeframe in TIMEFRAMES:\n",
    "        for prediction in PREDICTIONS:\n",
    "            if prediction < timeframe:\n",
    "                print(f\"Evaluating model predicting {prediction} days ahead using {img_type} images with {timeframe} days timeframe.\")\n",
    "\n",
    "                # Filter the data\n",
    "                data = labels[(labels['TimePrediction'] == prediction) &\n",
    "                              (labels['Image'].str.contains(img_type)) &\n",
    "                              (labels['Image'].str.contains(f'_{timeframe}_'))]\n",
    "                data = data.reset_index(drop=True)\n",
    "\n",
    "                # Load the model\n",
    "                model_filename = f\"models/{img_type}_{timeframe}_{prediction}.h5\"\n",
    "                #model_filename = f\"models/combined_{timeframe}_{prediction}.h5\"\n",
    "                model = load_model(model_filename)\n",
    "\n",
    "                X = np.array(data['Image_Array'].tolist())\n",
    "                lastPrice = np.array(data['LastPrice'].tolist())\n",
    "                futurePrice = np.array(data['FuturePrice'].tolist())\n",
    "                y = data['Label']\n",
    "\n",
    "                # Evaluate the model on test data\n",
    "                y_pred = model.predict(X)\n",
    "                # Convert predictions to binary: if > 0.5 then 1 else 0\n",
    "                y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "                \n",
    "                accuracy = accuracy_score(y, y_pred_binary)\n",
    "                precision = precision_score(y, y_pred_binary)\n",
    "                recall = recall_score(y, y_pred_binary)\n",
    "                f1_score = fbeta_score(y, y_pred_binary, beta=1)\n",
    "\n",
    "                y_test_array = y.values.ravel()  # Convert y_test to a 1D NumPy array if it's a pandas Series\n",
    "                correct_predictions = np.sum(y_pred_binary.ravel() == y_test_array)\n",
    "                hit_rate = correct_predictions / len(y_test_array)\n",
    "\n",
    "                # Calculate Rate of Return RoR\n",
    "                ror = np.where(y_pred_binary == 1, ((futurePrice - lastPrice)/lastPrice), 0)\n",
    "                # Drop all 0s from the array\n",
    "                ror = ror[ror != 0]\n",
    "                # Calculate average RoR\n",
    "                avg_ror = np.mean(ror)\n",
    "                \n",
    "                print(\"Evaluation Metrics:\")\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1 Score: {f1_score}\")\n",
    "                print(f\"Hit Rate: {hit_rate}\")\n",
    "                print(f\"Average RoR: {avg_ror}\")\n",
    "                \n",
    "                # Add the evaluation metrics to the DataFrame\n",
    "                evaluation_df = evaluation_df.append({\n",
    "                    'Image_Type': img_type,\n",
    "                    'Timeframe': timeframe,\n",
    "                    'Prediction': prediction,\n",
    "                    'Accuracy': accuracy,\n",
    "                    'Precision': precision,\n",
    "                    'Recall': recall,\n",
    "                    'F1_Score': f1_score,\n",
    "                    'Hit_Rate': hit_rate,\n",
    "                    'Average_RoR': avg_ror\n",
    "                }, ignore_index=True)\n",
    "\n",
    "# Save the evaluation DataFrame to a CSV file\n",
    "evaluation_df.to_csv('transfer_evaluation_scores.csv', index=False)\n",
    "print(\"Evaluation scores saved to 'tansfer_evaluation_scores.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.DataFrame(columns=['Timeframe', 'Prediction', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Hit_Rate', 'Average_RoR'])\n",
    "\n",
    "TIMEFRAMES = [14, 30, 90, 180, 365]\n",
    "PREDICTIONS = [5, 30, 90]\n",
    "IMG_TYPES = ['OHLC', 'ColoredOHLC', 'Line', 'AlgoTrading']\n",
    "\n",
    "for timeframe in TIMEFRAMES:\n",
    "    for prediction in PREDICTIONS:\n",
    "        if prediction < timeframe:\n",
    "            print(f\"Evaluating model predicting {prediction} days ahead with {timeframe} days timeframe.\")\n",
    "\n",
    "            # Filter the data\n",
    "            data = labels[(labels['TimePrediction'] == prediction) &\n",
    "                            (labels['Image'].str.contains(f'_{timeframe}_'))]\n",
    "            data = data.reset_index(drop=True)\n",
    "\n",
    "            # Start at same index as test data\n",
    "            split_index = int(len(data) * 0.7)\n",
    "            data = data[split_index:]\n",
    "\n",
    "            # Load the model\n",
    "            model_filename = f\"models/combined_{timeframe}_{prediction}.h5\"\n",
    "            model = load_model(model_filename)\n",
    "\n",
    "            X = np.array(data['Image_Array'].tolist()) / 255.0\n",
    "            lastPrice = np.array(data['LastPrice'].tolist())\n",
    "            futurePrice = np.array(data['FuturePrice'].tolist())\n",
    "            y = data['Label']\n",
    "\n",
    "            # Evaluate the model on test data\n",
    "            y_pred = model.predict(X)\n",
    "            # Convert predictions to binary: if > 0.5 then 1 else 0\n",
    "            y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "            \n",
    "            accuracy = accuracy_score(y, y_pred_binary)\n",
    "            precision = precision_score(y, y_pred_binary)\n",
    "            recall = recall_score(y, y_pred_binary)\n",
    "            f1_score = fbeta_score(y, y_pred_binary, beta=1)\n",
    "\n",
    "            y_test_array = y.values.ravel()  # Convert y_test to a 1D NumPy array if it's a pandas Series\n",
    "            correct_predictions = np.sum(y_pred_binary.ravel() == y_test_array)\n",
    "            hit_rate = correct_predictions / len(y_test_array)\n",
    "\n",
    "            # Calculate Rate of Return RoR\n",
    "            ror = np.where(y_pred_binary == 1, ((futurePrice - lastPrice)/lastPrice), 0)\n",
    "            # Drop all 0s from the array\n",
    "            ror = ror[ror != 0]\n",
    "            # Calculate average RoR\n",
    "            avg_ror = np.mean(ror)\n",
    "            \n",
    "            print(\"Evaluation Metrics:\")\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1 Score: {f1_score}\")\n",
    "            print(f\"Hit Rate: {hit_rate}\")\n",
    "            print(f\"Average RoR: {avg_ror}\")\n",
    "            \n",
    "            # Add the evaluation metrics to the DataFrame\n",
    "            evaluation_df = evaluation_df.append({\n",
    "                'Timeframe': timeframe,\n",
    "                'Prediction': prediction,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1_Score': f1_score,\n",
    "                'Hit_Rate': hit_rate,\n",
    "                'Average_RoR': avg_ror\n",
    "            }, ignore_index=True)\n",
    "\n",
    "# Save the evaluation DataFrame to a CSV file\n",
    "evaluation_df.to_csv('transfer_combined_evaluation_scores.csv', index=False)\n",
    "print(\"Evaluation scores saved to 'transfer_combined_evaluation_scores.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 5 days ahead with 14 days timeframe.\n",
      "12/12 [==============================] - 2s 113ms/step\n",
      "12/12 [==============================] - 1s 110ms/step\n",
      "12/12 [==============================] - 1s 111ms/step\n",
      "12/12 [==============================] - 1s 119ms/step\n",
      "12/12 [==============================] - 2s 153ms/step\n",
      "12/12 [==============================] - 2s 131ms/step\n",
      "12/12 [==============================] - 1s 122ms/step\n",
      "12/12 [==============================] - 1s 119ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 2s 145ms/step\n",
      "12/12 [==============================] - 2s 186ms/step\n",
      "12/12 [==============================] - 2s 157ms/step\n",
      "12/12 [==============================] - 2s 137ms/step\n",
      "12/12 [==============================] - 2s 140ms/step\n",
      "12/12 [==============================] - 2s 135ms/step\n",
      "12/12 [==============================] - 2s 125ms/step\n",
      "12/12 [==============================] - 2s 135ms/step\n",
      "12/12 [==============================] - 2s 134ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 2s 123ms/step\n",
      "12/12 [==============================] - 1s 118ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 130ms/step\n",
      "12/12 [==============================] - 1s 117ms/step\n",
      "12/12 [==============================] - 1s 119ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 125ms/step\n",
      "12/12 [==============================] - 1s 122ms/step\n",
      "12/12 [==============================] - 2s 131ms/step\n",
      "12/12 [==============================] - 2s 127ms/step\n",
      "12/12 [==============================] - 2s 123ms/step\n",
      "12/12 [==============================] - 2s 123ms/step\n",
      "12/12 [==============================] - 2s 121ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 131ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 119ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 2s 130ms/step\n",
      "12/12 [==============================] - 1s 122ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 118ms/step\n",
      "12/12 [==============================] - 2s 124ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 126ms/step\n",
      "12/12 [==============================] - 2s 128ms/step\n",
      "12/12 [==============================] - 2s 126ms/step\n",
      "12/12 [==============================] - 1s 118ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 129ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 118ms/step\n",
      "12/12 [==============================] - 2s 124ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 130ms/step\n",
      "12/12 [==============================] - 1s 118ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 2s 128ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 130ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 2s 124ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 129ms/step\n",
      "12/12 [==============================] - 1s 118ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 121ms/step\n",
      "12/12 [==============================] - 1s 117ms/step\n",
      "12/12 [==============================] - 2s 129ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 117ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 123ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 1s 117ms/step\n",
      "12/12 [==============================] - 2s 127ms/step\n",
      "12/12 [==============================] - 1s 120ms/step\n",
      "12/12 [==============================] - 2s 130ms/step\n",
      "12/12 [==============================] - 2s 123ms/step\n",
      "12/12 [==============================] - 1s 117ms/step\n",
      "12/12 [==============================] - 1s 119ms/step\n",
      "12/12 [==============================] - 2s 129ms/step\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "--------------------------------------------------\n",
      "Predicting 5 days ahead with 30 days timeframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constantinernstberger/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/constantinernstberger/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/constantinernstberger/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 4s 353ms/step\n",
      "11/11 [==============================] - 4s 375ms/step\n",
      "11/11 [==============================] - 4s 374ms/step\n",
      "11/11 [==============================] - 5s 425ms/step\n",
      "11/11 [==============================] - 4s 386ms/step\n",
      "11/11 [==============================] - 4s 386ms/step\n",
      "11/11 [==============================] - 4s 366ms/step\n",
      "11/11 [==============================] - 4s 377ms/step\n",
      "11/11 [==============================] - 4s 371ms/step\n",
      "11/11 [==============================] - 4s 369ms/step\n",
      "11/11 [==============================] - 4s 381ms/step\n",
      "11/11 [==============================] - 5s 410ms/step\n",
      "11/11 [==============================] - 5s 463ms/step\n",
      "11/11 [==============================] - 6s 495ms/step\n",
      "11/11 [==============================] - 4s 373ms/step\n",
      "11/11 [==============================] - 4s 370ms/step\n",
      "11/11 [==============================] - 4s 373ms/step\n",
      "11/11 [==============================] - 4s 376ms/step\n",
      "11/11 [==============================] - 4s 386ms/step\n",
      "11/11 [==============================] - 4s 370ms/step\n",
      "11/11 [==============================] - 4s 372ms/step\n",
      "11/11 [==============================] - 4s 382ms/step\n",
      "11/11 [==============================] - 4s 370ms/step\n",
      "11/11 [==============================] - 4s 369ms/step\n",
      "11/11 [==============================] - 4s 371ms/step\n",
      "11/11 [==============================] - 4s 389ms/step\n",
      "11/11 [==============================] - 4s 372ms/step\n",
      "11/11 [==============================] - 4s 391ms/step\n",
      "11/11 [==============================] - 4s 372ms/step\n",
      "11/11 [==============================] - 4s 383ms/step\n",
      "11/11 [==============================] - 4s 370ms/step\n",
      "11/11 [==============================] - 4s 374ms/step\n",
      "11/11 [==============================] - 4s 390ms/step\n",
      "11/11 [==============================] - 4s 379ms/step\n",
      "11/11 [==============================] - 4s 372ms/step\n",
      "11/11 [==============================] - 4s 375ms/step\n",
      "11/11 [==============================] - 4s 382ms/step\n",
      "11/11 [==============================] - 4s 373ms/step\n",
      "11/11 [==============================] - 5s 408ms/step\n",
      "11/11 [==============================] - 5s 441ms/step\n",
      "11/11 [==============================] - 4s 402ms/step\n",
      "11/11 [==============================] - 4s 382ms/step\n",
      "11/11 [==============================] - 4s 385ms/step\n",
      "11/11 [==============================] - 4s 377ms/step\n",
      "11/11 [==============================] - 5s 412ms/step\n",
      "11/11 [==============================] - 4s 387ms/step\n",
      "11/11 [==============================] - 4s 384ms/step\n",
      "11/11 [==============================] - 4s 393ms/step\n",
      "11/11 [==============================] - 4s 403ms/step\n",
      "11/11 [==============================] - 4s 382ms/step\n",
      "11/11 [==============================] - 4s 377ms/step\n",
      "11/11 [==============================] - 4s 379ms/step\n",
      "11/11 [==============================] - 4s 397ms/step\n",
      "11/11 [==============================] - 4s 383ms/step\n",
      "11/11 [==============================] - 4s 385ms/step\n",
      "11/11 [==============================] - 4s 382ms/step\n",
      "11/11 [==============================] - 4s 384ms/step\n",
      "11/11 [==============================] - 4s 377ms/step\n",
      "11/11 [==============================] - 4s 382ms/step\n",
      "11/11 [==============================] - 4s 400ms/step\n",
      "11/11 [==============================] - 4s 381ms/step\n",
      "11/11 [==============================] - 4s 379ms/step\n",
      "11/11 [==============================] - 4s 380ms/step\n",
      "11/11 [==============================] - 4s 392ms/step\n",
      "11/11 [==============================] - 4s 389ms/step\n",
      "11/11 [==============================] - 4s 382ms/step\n",
      "11/11 [==============================] - 4s 396ms/step\n",
      "11/11 [==============================] - 4s 379ms/step\n",
      "11/11 [==============================] - 4s 389ms/step\n",
      "11/11 [==============================] - 4s 380ms/step\n",
      "11/11 [==============================] - 5s 464ms/step\n",
      "11/11 [==============================] - 5s 438ms/step\n",
      "11/11 [==============================] - 5s 477ms/step\n",
      "11/11 [==============================] - 6s 522ms/step\n",
      "11/11 [==============================] - 5s 451ms/step\n",
      "11/11 [==============================] - 5s 461ms/step\n",
      "11/11 [==============================] - 4s 389ms/step\n",
      "11/11 [==============================] - 4s 392ms/step\n",
      "11/11 [==============================] - 5s 433ms/step\n",
      "11/11 [==============================] - 4s 394ms/step\n",
      "11/11 [==============================] - 5s 450ms/step\n",
      "11/11 [==============================] - 4s 400ms/step\n",
      "11/11 [==============================] - 4s 387ms/step\n",
      "11/11 [==============================] - 4s 391ms/step\n",
      "11/11 [==============================] - 5s 430ms/step\n",
      "11/11 [==============================] - 4s 409ms/step\n",
      "11/11 [==============================] - 4s 392ms/step\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n",
      "--------------------------------------------------\n",
      "Predicting 5 days ahead with 90 days timeframe.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/constantinernstberger/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/constantinernstberger/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/constantinernstberger/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 7s 645ms/step\n",
      "11/11 [==============================] - 7s 639ms/step\n",
      "11/11 [==============================] - 7s 645ms/step\n",
      " 1/11 [=>............................] - ETA: 8s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jx/r9zzxsjd7wxgmmn32r0l8cz40000gn/T/ipykernel_45131/3756585591.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                     \u001b[0;31m# Convert predictions to binary: if > 0.5 then 1 else 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0my_pred_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2552\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2554\u001b[0;31m                         \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2555\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2556\u001b[0m                             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    862\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/aiss/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train models on all images types and evaluate them based on timeframe and prediction\n",
    "\n",
    "evaluation_df = pd.DataFrame(columns=['Timeframe', 'Prediction', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'Hit_Rate', 'Average_RoR'])\n",
    "\n",
    "for timeframe in TIMEFRAMES:\n",
    "    for prediction in PREDICTIONS:\n",
    "        if prediction < timeframe:\n",
    "            print(f\"Predicting {prediction} days ahead with {timeframe} days timeframe.\")\n",
    "            \n",
    "            # Filter your data based on prediction, img_type, and timeframe\n",
    "            data = labels[(labels['TimePrediction'] == prediction) & (labels['Image'].str.contains(f'_{timeframe}_'))]\n",
    "            data = data.reset_index(drop=True)  # Reset the index to maintain temporal order\n",
    "\n",
    "            # Load model for timeframe and prediction\n",
    "            model = load_model(f\"models/combined_{timeframe}_{prediction}.h5\")\n",
    "\n",
    "            # Create a new array to store the combined predictions\n",
    "            y_pred_combined = []\n",
    "            y_combined = []\n",
    "\n",
    "            for date in data['Date'].unique():\n",
    "                for etf in NEW_DATA:\n",
    "                    new_data = data[(data['Date']==date) & (data['Image'].str.contains(f'{etf}_'))]\n",
    "                    new_data = data.reset_index(drop=True)\n",
    "                \n",
    "                    X = np.array(new_data['Image_Array'].tolist())/255.0\n",
    "                    # y equals the first label in the DataFrame\n",
    "                    y = new_data['Label'].iloc[0]\n",
    "                    y_combined.append(y)\n",
    "                    lastPrice = new_data['LastPrice'].iloc[0]\n",
    "                    futurePrice = new_data['FuturePrice'].iloc[0]\n",
    "                    \n",
    "                    # Evaluate the model\n",
    "                    y_pred = model.predict(X)\n",
    "                    # Convert predictions to binary: if > 0.5 then 1 else 0\n",
    "                    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "                    # If y_pred_binary contains more 1s than 0s, then predict 1, else predict 0\n",
    "                    if np.sum(y_pred_binary) > len(y_pred_binary) / 2:\n",
    "                        y_pred_combined.append(1)\n",
    "                    else:\n",
    "                        y_pred_combined.append(0)\n",
    "                \n",
    "            accuracy = accuracy_score(y_combined, y_pred_combined)\n",
    "            precision = precision_score(y_combined, y_pred_combined)\n",
    "            recall = recall_score(y_combined, y_pred_combined)\n",
    "            f1_score = fbeta_score(y_combined, y_pred_combined, beta=1)\n",
    "\n",
    "            y_array = np.array(y_combined)\n",
    "            correct_predictions = np.sum(np.array(y_pred_combined) == y_array)\n",
    "            hit_rate = correct_predictions / len(y_array)\n",
    "\n",
    "            # Calculate Rate of Return RoR\n",
    "            ror = np.where(y_pred_combined == 1, ((futurePrice - lastPrice)/lastPrice), 0)\n",
    "            # Drop all 0s from the array\n",
    "            ror = ror[ror != 0]\n",
    "            # Calculate average RoR\n",
    "            avg_ror = np.mean(ror)\n",
    "        \n",
    "            print(\"Evaluation Metrics:\")\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "            print(f\"Precision: {precision}\")\n",
    "            print(f\"Recall: {recall}\")\n",
    "            print(f\"F1 Score: {f1_score}\")\n",
    "            \n",
    "            # Add the evaluation metrics to the DataFrame\n",
    "            evaluation_df = evaluation_df.append({\n",
    "                'Timeframe': timeframe,\n",
    "                'Prediction': prediction,\n",
    "                'Accuracy': accuracy,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1_Score': f1_score,\n",
    "                'Hit_Rate': hit_rate,\n",
    "                'Average_RoR': avg_ror\n",
    "            }, ignore_index=True)\n",
    "        \n",
    "            print(\"--------------------------------------------------\")\n",
    "\n",
    "# Save the evaluation DataFrame to a CSV file\n",
    "evaluation_df.to_csv('combined_prediction_evaluation_scores.csv', index=False)\n",
    "print(\"Evaluation scores saved to 'combined_prediction_evaluation_scores.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiss",
   "language": "python",
   "name": "aiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
